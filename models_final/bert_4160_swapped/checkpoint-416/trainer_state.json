{
  "best_global_step": 416,
  "best_metric": 0.8390184006373607,
  "best_model_checkpoint": "models_final/bert_4160_swapped\\checkpoint-416",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 416,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04807692307692308,
      "grad_norm": 8.091161727905273,
      "learning_rate": 4.5e-06,
      "loss": 1.3903,
      "step": 10
    },
    {
      "epoch": 0.09615384615384616,
      "grad_norm": 8.956514358520508,
      "learning_rate": 9.5e-06,
      "loss": 1.104,
      "step": 20
    },
    {
      "epoch": 0.14423076923076922,
      "grad_norm": 4.1223649978637695,
      "learning_rate": 1.45e-05,
      "loss": 0.9108,
      "step": 30
    },
    {
      "epoch": 0.19230769230769232,
      "grad_norm": 7.620124340057373,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 0.8508,
      "step": 40
    },
    {
      "epoch": 0.2403846153846154,
      "grad_norm": 3.837188720703125,
      "learning_rate": 2.45e-05,
      "loss": 1.0009,
      "step": 50
    },
    {
      "epoch": 0.28846153846153844,
      "grad_norm": 5.357044696807861,
      "learning_rate": 2.95e-05,
      "loss": 0.7707,
      "step": 60
    },
    {
      "epoch": 0.33653846153846156,
      "grad_norm": 4.967607021331787,
      "learning_rate": 3.45e-05,
      "loss": 0.9637,
      "step": 70
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 4.878740310668945,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.7961,
      "step": 80
    },
    {
      "epoch": 0.4326923076923077,
      "grad_norm": 8.923649787902832,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.7257,
      "step": 90
    },
    {
      "epoch": 0.4807692307692308,
      "grad_norm": 4.44126558303833,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.5935,
      "step": 100
    },
    {
      "epoch": 0.5288461538461539,
      "grad_norm": 3.360193967819214,
      "learning_rate": 4.9141221374045806e-05,
      "loss": 0.5672,
      "step": 110
    },
    {
      "epoch": 0.5769230769230769,
      "grad_norm": 2.8902978897094727,
      "learning_rate": 4.818702290076336e-05,
      "loss": 0.6482,
      "step": 120
    },
    {
      "epoch": 0.625,
      "grad_norm": 7.7236552238464355,
      "learning_rate": 4.723282442748092e-05,
      "loss": 0.5716,
      "step": 130
    },
    {
      "epoch": 0.6730769230769231,
      "grad_norm": 5.236418724060059,
      "learning_rate": 4.6278625954198474e-05,
      "loss": 0.4658,
      "step": 140
    },
    {
      "epoch": 0.7211538461538461,
      "grad_norm": 4.953857898712158,
      "learning_rate": 4.532442748091603e-05,
      "loss": 0.4178,
      "step": 150
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 11.250697135925293,
      "learning_rate": 4.437022900763359e-05,
      "loss": 0.6228,
      "step": 160
    },
    {
      "epoch": 0.8173076923076923,
      "grad_norm": 10.12829303741455,
      "learning_rate": 4.341603053435115e-05,
      "loss": 0.4816,
      "step": 170
    },
    {
      "epoch": 0.8653846153846154,
      "grad_norm": 9.5546236038208,
      "learning_rate": 4.2461832061068705e-05,
      "loss": 0.5638,
      "step": 180
    },
    {
      "epoch": 0.9134615384615384,
      "grad_norm": 4.084653854370117,
      "learning_rate": 4.150763358778626e-05,
      "loss": 0.4643,
      "step": 190
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 10.823670387268066,
      "learning_rate": 4.055343511450382e-05,
      "loss": 0.4509,
      "step": 200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8149038461538461,
      "eval_f1": 0.8124754344176579,
      "eval_loss": 0.4869830012321472,
      "eval_runtime": 62.6901,
      "eval_samples_per_second": 6.636,
      "eval_steps_per_second": 0.829,
      "step": 208
    },
    {
      "epoch": 1.0096153846153846,
      "grad_norm": 4.72085428237915,
      "learning_rate": 3.9599236641221373e-05,
      "loss": 0.5265,
      "step": 210
    },
    {
      "epoch": 1.0576923076923077,
      "grad_norm": 4.266630172729492,
      "learning_rate": 3.8645038167938936e-05,
      "loss": 0.3117,
      "step": 220
    },
    {
      "epoch": 1.1057692307692308,
      "grad_norm": 8.600929260253906,
      "learning_rate": 3.7690839694656486e-05,
      "loss": 0.4322,
      "step": 230
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 15.960583686828613,
      "learning_rate": 3.673664122137405e-05,
      "loss": 0.4774,
      "step": 240
    },
    {
      "epoch": 1.2019230769230769,
      "grad_norm": 11.662418365478516,
      "learning_rate": 3.5782442748091604e-05,
      "loss": 0.4293,
      "step": 250
    },
    {
      "epoch": 1.25,
      "grad_norm": 6.6614298820495605,
      "learning_rate": 3.482824427480916e-05,
      "loss": 0.4652,
      "step": 260
    },
    {
      "epoch": 1.2980769230769231,
      "grad_norm": 4.610633373260498,
      "learning_rate": 3.387404580152672e-05,
      "loss": 0.3643,
      "step": 270
    },
    {
      "epoch": 1.3461538461538463,
      "grad_norm": 8.00795841217041,
      "learning_rate": 3.291984732824427e-05,
      "loss": 0.2764,
      "step": 280
    },
    {
      "epoch": 1.3942307692307692,
      "grad_norm": 8.83777904510498,
      "learning_rate": 3.1965648854961835e-05,
      "loss": 0.3418,
      "step": 290
    },
    {
      "epoch": 1.4423076923076923,
      "grad_norm": 6.2401204109191895,
      "learning_rate": 3.101145038167939e-05,
      "loss": 0.3238,
      "step": 300
    },
    {
      "epoch": 1.4903846153846154,
      "grad_norm": 3.3944380283355713,
      "learning_rate": 3.005725190839695e-05,
      "loss": 0.2922,
      "step": 310
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 8.617790222167969,
      "learning_rate": 2.9103053435114507e-05,
      "loss": 0.3526,
      "step": 320
    },
    {
      "epoch": 1.5865384615384617,
      "grad_norm": 5.1004109382629395,
      "learning_rate": 2.814885496183206e-05,
      "loss": 0.3892,
      "step": 330
    },
    {
      "epoch": 1.6346153846153846,
      "grad_norm": 4.0068230628967285,
      "learning_rate": 2.719465648854962e-05,
      "loss": 0.4231,
      "step": 340
    },
    {
      "epoch": 1.6826923076923077,
      "grad_norm": 3.5318245887756348,
      "learning_rate": 2.624045801526718e-05,
      "loss": 0.3803,
      "step": 350
    },
    {
      "epoch": 1.7307692307692308,
      "grad_norm": 3.490878105163574,
      "learning_rate": 2.5286259541984734e-05,
      "loss": 0.3321,
      "step": 360
    },
    {
      "epoch": 1.7788461538461537,
      "grad_norm": 1.2154021263122559,
      "learning_rate": 2.433206106870229e-05,
      "loss": 0.2754,
      "step": 370
    },
    {
      "epoch": 1.8269230769230769,
      "grad_norm": 6.39715576171875,
      "learning_rate": 2.3377862595419846e-05,
      "loss": 0.3046,
      "step": 380
    },
    {
      "epoch": 1.875,
      "grad_norm": 11.444186210632324,
      "learning_rate": 2.2423664122137406e-05,
      "loss": 0.3125,
      "step": 390
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 9.115213394165039,
      "learning_rate": 2.1469465648854965e-05,
      "loss": 0.4068,
      "step": 400
    },
    {
      "epoch": 1.9711538461538463,
      "grad_norm": 10.13743782043457,
      "learning_rate": 2.0515267175572518e-05,
      "loss": 0.3456,
      "step": 410
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8413461538461539,
      "eval_f1": 0.8390184006373607,
      "eval_loss": 0.48722681403160095,
      "eval_runtime": 60.3528,
      "eval_samples_per_second": 6.893,
      "eval_steps_per_second": 0.862,
      "step": 416
    }
  ],
  "logging_steps": 10,
  "max_steps": 624,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 437557613681664.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
